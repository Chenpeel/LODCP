{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "960e0f2b",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf04c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm  # 进度条支持\n",
    "import yaml  # 替代JSON读取.env\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import gc  # 垃圾回收\n",
    "\n",
    "# 加载配置\n",
    "def load_config(config_path=\"config.yml\"):\n",
    "    with open(config_path) as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "class DatasetProcessor:\n",
    "    def __init__(self, batch_size=100, num_workers=4, target_size=(512, 256)):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def process_kitti(self, kitti_path, cache_dir=None):\n",
    "        \"\"\"\n",
    "        分批处理KITTI数据集，支持缓存\n",
    "        Args:\n",
    "            kitti_path: KITTI数据集根目录\n",
    "            cache_dir: 预处理结果缓存目录\n",
    "        Yields:\n",
    "            (images, masks) 批次数据\n",
    "        \"\"\"\n",
    "        if cache_dir and os.path.exists(os.path.join(cache_dir, \"kitti_cache.npz\")):\n",
    "            data = np.load(os.path.join(cache_dir, \"kitti_cache.npz\"))\n",
    "            yield data[\"images\"], data[\"masks\"]\n",
    "            return\n",
    "\n",
    "        image_dir = os.path.join(kitti_path, \"data_road/training/image_2\")\n",
    "        label_dir = os.path.join(kitti_path, \"data_road/training/gt_image_2\")\n",
    "\n",
    "        img_files = [f for f in os.listdir(image_dir) if f.endswith(\".png\")]\n",
    "        total_files = len(img_files)\n",
    "\n",
    "        # 分批处理\n",
    "        for i in tqdm(range(0, total_files, self.batch_size), desc=\"Processing KITTI\"):\n",
    "            batch_files = img_files[i:i+self.batch_size]\n",
    "            images, masks = [], []\n",
    "\n",
    "            with ThreadPoolExecutor(max_workers=self.num_workers) as executor:\n",
    "                results = list(executor.map(\n",
    "                    lambda f: self._process_kitti_image(image_dir, label_dir, f),\n",
    "                    batch_files\n",
    "                ))\n",
    "\n",
    "            for img, mask in results:\n",
    "                if img is not None and mask is not None:\n",
    "                    images.append(img)\n",
    "                    masks.append(mask)\n",
    "\n",
    "            if images:\n",
    "                images = np.array(images)\n",
    "                masks = np.array(masks)\n",
    "\n",
    "                if cache_dir and i == 0:  # 只缓存第一批作为示例\n",
    "                    os.makedirs(cache_dir, exist_ok=True)\n",
    "                    np.savez(os.path.join(cache_dir, \"kitti_cache.npz\"),\n",
    "                            images=images, masks=masks)\n",
    "\n",
    "                yield images, masks\n",
    "                del images, masks\n",
    "                gc.collect()\n",
    "\n",
    "    def _process_kitti_image(self, image_dir, label_dir, img_file):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            return None, None\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, self.target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        base_name = os.path.splitext(img_file)[0]\n",
    "        label_path = os.path.join(label_dir, f\"{base_name}_road.png\")\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            mask = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.resize(mask, self.target_size, interpolation=cv2.INTER_NEAREST)\n",
    "            _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "            return img, mask\n",
    "        return None, None\n",
    "\n",
    "    def process_bdd100k(self, bdd100k_path, json_file=\"det_v2_train_release.json\"):\n",
    "        \"\"\"\n",
    "        分批处理BDD100K数据集\n",
    "        Args:\n",
    "            bdd100k_path: 数据集根目录\n",
    "            json_file: 标注文件名\n",
    "        Yields:\n",
    "            (images, masks) 批次数据\n",
    "        \"\"\"\n",
    "        label_path = os.path.join(bdd100k_path, \"labels\", json_file)\n",
    "        with open(label_path) as f:\n",
    "            annotations = json.load(f)\n",
    "        if \"train\" in json_file.lower():\n",
    "            split = \"train\"\n",
    "        elif \"val\" in json_file.lower():\n",
    "            split = \"val\"\n",
    "        else:\n",
    "            split = \"train\"\n",
    "\n",
    "        img_dir = os.path.join(bdd100k_path, \"bdd100k\", \"bdd100k\", \"images\", \"100k\", split)\n",
    "        total_anns = len(annotations)\n",
    "\n",
    "        # 分批处理\n",
    "        for i in tqdm(range(0, total_anns, self.batch_size), desc=\"Processing BDD100K\"):\n",
    "            batch_anns = annotations[i:i+self.batch_size]\n",
    "            images, masks = [], []\n",
    "\n",
    "            with ThreadPoolExecutor(max_workers=self.num_workers) as executor:\n",
    "                results = list(executor.map(\n",
    "                    lambda ann: self._process_bdd_annotation(ann, img_dir),\n",
    "                    batch_anns\n",
    "                ))\n",
    "\n",
    "            for img, mask in results:\n",
    "                if img is not None and mask is not None:\n",
    "                    images.append(img)\n",
    "                    masks.append(mask)\n",
    "\n",
    "            if images:\n",
    "                yield np.array(images), np.array(masks)\n",
    "                del images, masks\n",
    "                gc.collect()\n",
    "\n",
    "    def _process_bdd_annotation(self, ann, img_dir):\n",
    "        img_path = os.path.join(img_dir, ann[\"name\"])\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = img.resize(self.target_size)\n",
    "\n",
    "            mask = Image.new(\"L\", self.target_size, 0)\n",
    "            draw = ImageDraw.Draw(mask)\n",
    "\n",
    "            for label in ann[\"labels\"]:\n",
    "                if label[\"category\"] == \"drivable area\":\n",
    "                    for poly in label.get(\"poly2d\", []):\n",
    "                        # 坐标缩放至target_size\n",
    "                        scaled_vertices = [\n",
    "                            (x * self.target_size[0] / ann[\"width\"],\n",
    "                             y * self.target_size[1] / ann[\"height\"])\n",
    "                            for x, y in poly[\"vertices\"]\n",
    "                        ]\n",
    "                        draw.polygon(scaled_vertices, fill=255)\n",
    "\n",
    "            return np.array(img), np.array(mask)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "def combine_and_save_datasets(kitti_gen, bdd_gen, output_dir):\n",
    "    \"\"\"\n",
    "    合并数据集并保存为多个小文件\n",
    "    Args:\n",
    "        kitti_gen: KITTI数据生成器(可为None)\n",
    "        bdd_gen: BDD100K数据生成器(可为None)\n",
    "        output_dir: 输出目录\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    batch_num = 0\n",
    "\n",
    "    # 统一使用 batch_ 前缀\n",
    "    if kitti_gen is not None:\n",
    "        for kitti_imgs, kitti_masks in kitti_gen:\n",
    "            np.savez(os.path.join(output_dir, f\"batch_{batch_num}.npz\"),\n",
    "                    images=kitti_imgs, masks=kitti_masks)\n",
    "            batch_num += 1\n",
    "\n",
    "    if bdd_gen is not None:\n",
    "        for bdd_imgs, bdd_masks in bdd_gen:\n",
    "            np.savez(os.path.join(output_dir, f\"batch_{batch_num}.npz\"),\n",
    "                    images=bdd_imgs, masks=bdd_masks)\n",
    "            batch_num += 1\n",
    "\n",
    "    # 创建合并后的数据加载器\n",
    "    class MergedDataset:\n",
    "        def __init__(self, output_dir):\n",
    "            self.output_dir = output_dir\n",
    "            self.batch_files = sorted(\n",
    "                [f for f in os.listdir(output_dir) if f.endswith(\".npz\")],\n",
    "                key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0])  # 取最后一部分的数字\n",
    "            )\n",
    "        def __iter__(self):\n",
    "            for batch_file in self.batch_files:\n",
    "                data = np.load(os.path.join(self.output_dir, batch_file))\n",
    "                yield data[\"images\"], data[\"masks\"]\n",
    "\n",
    "    return MergedDataset(output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置参数\n",
    "    target_size =tuple(list(config.get(\"target_size\"))[::-1])\n",
    "\n",
    "    processor = DatasetProcessor(\n",
    "        batch_size=config.get(\"batch_size\", 289),\n",
    "        num_workers=config.get(\"num_workers\", 8),\n",
    "        target_size=target_size\n",
    "    )\n",
    "    # 创建数据生成器\n",
    "    kitti_gen = processor.process_kitti(\n",
    "        config[\"kitti_path\"],\n",
    "        cache_dir=config.get(\"cache_dir\"))\n",
    "\n",
    "    train_bdd_gen = processor.process_bdd100k(\n",
    "        config[\"bdd100k_path\"],\n",
    "        json_file=config.get(\"bdd_json_train\", \"det_v2_train_release.json\"))\n",
    "\n",
    "    # 合并并保存数据集\n",
    "    train_dir = config.get(\"train_dir\", \"processed_data/train\")\n",
    "    train_dataset = combine_and_save_datasets(kitti_gen, train_bdd_gen, train_dir)\n",
    "\n",
    "    val_bdd_gen = processor.process_bdd100k(\n",
    "        config[\"bdd100k_path\"],\n",
    "        json_file=config.get(\"bdd_json_val\", \"det_v2_val_release.json\"))\n",
    "    val_dir = config.get(\"val_dir\", \"processed_data/val\")\n",
    "    val_dataset = combine_and_save_datasets(None, val_bdd_gen, val_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b4acf",
   "metadata": {},
   "source": [
    "## TinyLANE-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173459cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def dice_coeff(y_true, y_pred, smooth=1):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "def build_tiny_unet(input_shape=(256, 512, 3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # 编码器\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x1 = x\n",
    "    x = layers.MaxPool2D(2)(x)  # 128x256\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x2 = x\n",
    "    x = layers.MaxPool2D(2)(x)  # 64x128\n",
    "\n",
    "    # 中间层\n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # 解码器\n",
    "    x = layers.UpSampling2D(2)(x)  # 128x256\n",
    "    x = layers.Concatenate()([x, x2])\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.UpSampling2D(2)(x)  # 256x512\n",
    "    x = layers.Concatenate()([x, x1])\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # 输出层\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name='TinyUNet')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c715dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "import tensorflow as tf\n",
    "\n",
    "class NpzDataset:\n",
    "    def __init__(self, npz_dir, batch_size=8, target_size=(256, 512), augment=False):\n",
    "        self.npz_files = sorted(glob(f\"{npz_dir}/*.npz\"))\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.augment = augment\n",
    "        self.augmentation = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.2),\n",
    "            A.Affine(scale=0.1, rotate=10, p=0.3),\n",
    "        ])\n",
    "        self._count_samples()\n",
    "\n",
    "    def _count_samples(self):\n",
    "        self.total_samples = 0\n",
    "        for npz_file in self.npz_files:\n",
    "            with np.load(npz_file) as data:\n",
    "                self.total_samples += len(data['images'])\n",
    "\n",
    "    def _process_data(self, npz_file):\n",
    "        data = np.load(npz_file)\n",
    "        images = data['images'].astype('float32') / 255.0\n",
    "        masks = data['masks'].astype('float32') / 255.0\n",
    "\n",
    "        if self.augment:\n",
    "            images, masks = self._augment_batch(images, masks)\n",
    "\n",
    "        # 调整尺寸\n",
    "        images = tf.image.resize(images, self.target_size)\n",
    "        masks = tf.image.resize(masks[..., tf.newaxis], self.target_size)[..., 0]\n",
    "\n",
    "        return images, masks\n",
    "\n",
    "    def _augment_batch(self, images, masks):\n",
    "        augmented_images = []\n",
    "        augmented_masks = []\n",
    "\n",
    "        for image, mask in zip(images, masks):\n",
    "            augmented = self.augmentation(image=image, mask=mask)\n",
    "            augmented_images.append(augmented['image'])\n",
    "            augmented_masks.append(augmented['mask'])\n",
    "\n",
    "        return np.array(augmented_images), np.array(augmented_masks)\n",
    "    def to_tf_dataset(self):\n",
    "        all_images = []\n",
    "        all_masks = []\n",
    "\n",
    "        for npz_file in self.npz_files:\n",
    "            data = np.load(npz_file)\n",
    "            images = data['images'].astype('float32') / 255.0\n",
    "            masks = data['masks'].astype('float32') / 255.0\n",
    "\n",
    "            # Debug: 检查数据是否为空\n",
    "            print(f\"Processing {npz_file}:\")\n",
    "            print(f\"  - images shape: {images.shape}\")\n",
    "            print(f\"  - masks shape: {masks.shape}\")\n",
    "\n",
    "            if images.size == 0 or masks.size == 0:\n",
    "                print(f\"⚠️ Warning: Empty data in {npz_file}, skipping...\")\n",
    "                continue  # 跳过空数据\n",
    "\n",
    "            # 确保正确的维度 (batch, height, width, channels)\n",
    "            if len(images.shape) == 3:  # (H, W, C)\n",
    "                images = np.expand_dims(images, axis=0)\n",
    "            elif len(images.shape) == 2:  # (H, W)\n",
    "                images = np.expand_dims(images, axis=-1)\n",
    "                images = np.expand_dims(images, axis=0)\n",
    "\n",
    "            if len(masks.shape) == 2:  # (H, W)\n",
    "                masks = np.expand_dims(masks, axis=-1)\n",
    "                masks = np.expand_dims(masks, axis=0)\n",
    "            elif len(masks.shape) == 3 and masks.shape[-1] != 1:  # (H, W, ?)\n",
    "                masks = np.expand_dims(masks, axis=-1)\n",
    "\n",
    "            if self.augment:\n",
    "                images, masks = self._augment_batch(images, masks)\n",
    "\n",
    "            images = tf.image.resize(images, self.target_size)\n",
    "            masks = tf.image.resize(masks, self.target_size)\n",
    "\n",
    "            all_images.append(images)\n",
    "            all_masks.append(masks)\n",
    "\n",
    "        if not all_images:\n",
    "            raise ValueError(\"⚠️ No valid data found in any .npz file!\")\n",
    "\n",
    "        all_images = tf.concat(all_images, axis=0)\n",
    "        all_masks = tf.concat(all_masks, axis=0)\n",
    "\n",
    "        return tf.data.Dataset.from_tensor_slices(\n",
    "            (all_images, all_masks)\n",
    "        ).batch(self.batch_size)\n",
    "\n",
    "    @property\n",
    "    def steps_per_epoch(self):\n",
    "        return int(np.ceil(self.total_samples / self.batch_size))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
